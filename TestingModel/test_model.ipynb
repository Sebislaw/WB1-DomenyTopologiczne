{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-16T06:08:21.191091Z",
     "start_time": "2024-06-16T06:08:20.080277Z"
    }
   },
   "source": [
    "import straw\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "from scipy import ndimage\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:06:06.519220Z",
     "start_time": "2024-06-16T06:06:06.414173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "\n",
    "    ###########################################################################################\n",
    "\n",
    "    def read_data(self, paht_to_file, chromosome, resolution, smoothing, smoothing_param):\n",
    "\n",
    "        def get_df(normalisation, file_path, chromosome_1, chromosome_2, length_unit, resolution):\n",
    "            # Data from https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE63525\n",
    "            # GSE63525_GM12878_diploid_maternal.hic\n",
    "            df = straw.straw(normalisation, file_path, chromosome_1, chromosome_2, length_unit, resolution)\n",
    "            # example values: \"KR\", \"../Data/GSE63525_GM12878_diploid_maternal.hic\", \"11\", \"11\", \"BP\", 500000\n",
    "\n",
    "            # Transforming the list to a data frame with three columns.\n",
    "            # Origininally the raed data is a list of three lists, \n",
    "            # each with the same length (list of x, y and counts).\n",
    "            df = pd.DataFrame(df).transpose()\n",
    "            df.columns = ['x', 'y', 'count']\n",
    "\n",
    "            return df\n",
    "\n",
    "        def is_symmetric(matrix):\n",
    "            \"\"\"\n",
    "            Check if a matrix is symmetric.\n",
    "\n",
    "            Parameters:\n",
    "                matrix (list of lists): The input matrix.\n",
    "\n",
    "            Returns:\n",
    "                bool: True if the matrix is symmetric, False otherwise.\n",
    "            \"\"\"\n",
    "            n = len(matrix)\n",
    "            if n != len(matrix[0]):\n",
    "                return False  # Matrix is not square, so it can't be symmetric\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(i + 1, n):\n",
    "                    if matrix[i][j] != matrix[j][i]:\n",
    "                        return False  # If corresponding elements are not equal, matrix is not symmetric\n",
    "\n",
    "            return True\n",
    "\n",
    "        def make_symmetric(matrix):\n",
    "            \"\"\"\n",
    "            Make a matrix symmetric by copying the lower triangle to the upper triangle.\n",
    "\n",
    "            Parameters:\n",
    "                matrix (list of lists): The input matrix.\n",
    "\n",
    "            Returns:\n",
    "                list of lists: The corrected symmetric matrix.\n",
    "            \"\"\"\n",
    "            n = len(matrix)\n",
    "            if n != len(matrix[0]):\n",
    "                # raise ValueError(\"Input matrix is not square\")\n",
    "                # cut the matrix to square\n",
    "                min_shape = min(n, len(matrix[0]))\n",
    "                matrix = matrix[:min_shape, :min_shape]\n",
    "            else:\n",
    "                min_shape = n\n",
    "\n",
    "            for i in range(min_shape):\n",
    "                for j in range(i + 1, min_shape):\n",
    "                    matrix[j][i] = matrix[i][j]\n",
    "\n",
    "            return matrix\n",
    "\n",
    "        def median_filtering(matrix, size=3):\n",
    "            \"\"\"\n",
    "            Apply median filtering to a sparse matrix.\n",
    "\n",
    "            Parameters:\n",
    "                matrix (numpy.ndarray): The input matrix.\n",
    "                size (int): The size of the median filter kernel.\n",
    "\n",
    "            Returns:\n",
    "                numpy.ndarray: The smoothed matrix.\n",
    "            \"\"\"\n",
    "            smoothed_matrix = ndimage.median_filter(matrix, size=size)\n",
    "            return smoothed_matrix\n",
    "\n",
    "        def gaussian_smoothing(matrix, sigma=1):\n",
    "            \"\"\"\n",
    "            Apply Gaussian smoothing to a sparse matrix.\n",
    "\n",
    "            Parameters:\n",
    "                matrix (numpy.ndarray): The input matrix.\n",
    "                sigma (float): Standard deviation of the Gaussian filter.\n",
    "\n",
    "            Returns:\n",
    "                numpy.ndarray: The smoothed matrix.\n",
    "            \"\"\"\n",
    "            smoothed_matrix = ndimage.gaussian_filter(matrix, sigma=sigma)\n",
    "            return smoothed_matrix\n",
    "\n",
    "        def mean_smoothing(matrix, size=1):\n",
    "            \"\"\"\n",
    "            Apply Mean smoothing to a sparse matrix.\n",
    "\n",
    "            Parameters:\n",
    "                matrix (numpy.ndarray): The input matrix.\n",
    "                sigma (float): Standard deviation of the Gaussian filter.\n",
    "\n",
    "            Returns:\n",
    "                numpy.ndarray: The smoothed matrix.\n",
    "            \"\"\"\n",
    "            smoothed_matrix = ndimage.uniform_filter(matrix, size)\n",
    "            return smoothed_matrix\n",
    "\n",
    "        def general_information_about_data(df):\n",
    "            print(f'Number of rows: {len(df)}')\n",
    "            print(f\"Number of unique x and y values: {df['x'].nunique()}, {df['y'].nunique()}\")\n",
    "            print(f\"Mean interactions per fragment {df['count'].mean()}\")\n",
    "            print(f\"Median of interactions per fragment {df['count'].median()}\")\n",
    "\n",
    "        df = get_df(\"KR\", paht_to_file, chromosome, chromosome, \"BP\", resolution)\n",
    "        # print('df', df)\n",
    "        general_information_about_data(df)\n",
    "        data = np.nan_to_num(df.pivot(index='x', columns='y', values='count').to_numpy(),\n",
    "                             copy=True, nan=0.0, posinf=None, neginf=None)\n",
    "        # print('data', type(data), data)\n",
    "\n",
    "        # if not is_symmetric(data):\n",
    "        data = make_symmetric(data)\n",
    "\n",
    "        # print('data2', type(data), data)    \n",
    "        data = data + data.T - np.diag(data.diagonal())\n",
    "\n",
    "        if smoothing == 1:\n",
    "            data = median_filtering(data, smoothing_param)\n",
    "        elif smoothing == 2:\n",
    "            data = gaussian_smoothing(data, smoothing_param)\n",
    "        elif smoothing == 3:\n",
    "            data = mean_smoothing(data, smoothing_param)\n",
    "        else:\n",
    "            print('Selected no smoothing. To select:\\n\\\n",
    "                    median_filtering - type 1\\n\\\n",
    "                    gaussian_smoothing - type 2\\n\\\n",
    "                    mean_smoothing - type 3.'\n",
    "                  )\n",
    "\n",
    "        if not is_symmetric(data):\n",
    "            data = make_symmetric(data)\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    ###########################################################################################\n",
    "\n",
    "    def draw_contact_matrix(self):\n",
    "        sns.set_theme(rc={'figure.figsize':(4, 4)})\n",
    "        sns.heatmap(self.data, cbar=False, vmin=0, square=True, norm=LogNorm(), cmap='Reds')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(True)\n",
    "        plt.show()\n",
    "\n",
    "    ###########################################################################################\n",
    "\n",
    "    def draw_contact_matrix_with_boundries(self, tad_boundaries):\n",
    "        sns.set_theme(rc={'figure.figsize':(4, 4)})\n",
    "        sns.heatmap(self.data, cbar=False, vmin=0, square=True, norm=LogNorm(), cmap='Reds')\n",
    "        for boundary in tad_boundaries:\n",
    "            plt.axvline(x=boundary, color='blue', linestyle='--')\n",
    "            plt.axhline(y=boundary, color='blue', linestyle='--')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(True)\n",
    "        plt.show()\n",
    "\n",
    "    ###########################################################################################\n",
    "\n",
    "    def get_diagonal_averages(self, max_r):\n",
    "        \"\"\"\n",
    "        Compute the average of sums of elements inside square submatrices along the diagonal of a given matrix\n",
    "        per element in the submatrix.\n",
    "\n",
    "        Parameters:\n",
    "            matrix (numpy.ndarray): The input matrix.\n",
    "            r (int): The size of the square submatrix.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of sums of elements inside each square submatrix along the diagonal.\n",
    "        \"\"\"\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for r in range(1, max_r):\n",
    "            sums = []\n",
    "            n = self.data.shape[0]\n",
    "\n",
    "            for i in range(0, n - r + 1):\n",
    "                submatrix = self.data[i:i+r, i:i+r]\n",
    "                submatrix_sum = np.sum(submatrix)/(r*r)\n",
    "                sums.append(submatrix_sum)\n",
    "\n",
    "            result.append(sums)\n",
    "\n",
    "        return result\n",
    "\n",
    "    ###########################################################################################\n",
    "\n",
    "    def get_tad_boundaries(self, max_num_of_tads, min_tad_size, smoothing_param, max_r, sums):\n",
    "\n",
    "        def process_lists(list_of_lists, threshold_strength=1):\n",
    "            \"\"\"\n",
    "            Process each list in the list of lists:\n",
    "            1. Separate values greater than the mean of the list.\n",
    "            2. Find continuous sequences where more than 10% of all values are present.\n",
    "            3. Find the maximum value for such sequences.\n",
    "            4. Place the indexes corresponding to max values in a list.\n",
    "            5. Place these lists in a list and return the result.\n",
    "\n",
    "            Parameters:\n",
    "                list_of_lists (list of lists): The input list of lists.\n",
    "\n",
    "            Returns:\n",
    "                list: A list containing lists of indexes corresponding to maximum values for each list.\n",
    "            \"\"\"\n",
    "            result = []\n",
    "\n",
    "            for lst in list_of_lists:\n",
    "                threshold = np.mean(lst)*threshold_strength\n",
    "                continuous_sequences_max = []\n",
    "\n",
    "                # Separate values greater than the mean (rest set to 0)\n",
    "                for i in range(len(lst)):\n",
    "                    if lst[i] < threshold:\n",
    "                        lst[i] = 0\n",
    "\n",
    "                # Find continuous sequences (separator is 0) where more than 10% of all values are present\n",
    "                continuous_sequences = [0] * len(lst)\n",
    "\n",
    "                sequence_length = math.floor(len(lst)*0.1+1)\n",
    "                for i in range(len(lst) - sequence_length + 1):\n",
    "                    if all(lst[i+j] != 0 for j in range(sequence_length)):\n",
    "                        continuous_sequences[i:i+sequence_length] = lst[i:i+sequence_length]\n",
    "\n",
    "\n",
    "                # Fina max values in sequences (separated by 0) and  change non-max values to 0\n",
    "                start = 0\n",
    "                for i in range(len(continuous_sequences)):\n",
    "                    if continuous_sequences[i] == 0:\n",
    "                        if start != i:\n",
    "                            max_value = max(continuous_sequences[start:i])\n",
    "                            continuous_sequences_max.extend([0 if val != max_value else val for val in continuous_sequences[start:i]])\n",
    "                        continuous_sequences_max.append(0)  # Append the 0 separator\n",
    "                        start = i + 1\n",
    "                    elif i == len(continuous_sequences) - 1:\n",
    "                        max_value = max(continuous_sequences[start:i + 1])\n",
    "                        continuous_sequences_max.extend([0 if val != max_value else val for val in continuous_sequences[start:i + 1]])\n",
    "\n",
    "                # Find all indexes of non-0 values\n",
    "                result.append([i for i, val in enumerate(continuous_sequences_max) if val != 0])\n",
    "            return result\n",
    "\n",
    "        def create_result_array(IN, tad_num, dist, information = False):\n",
    "            \"\"\"\n",
    "            Create a RESULT array with S elements from the input array IN,\n",
    "            maintaining the distance constraint K as described.\n",
    "\n",
    "            Parameters:\n",
    "            IN (list): The input array.\n",
    "            tad_num (int): The number of elements required in the RESULT array.\n",
    "            dist (int): The distance constraint between elements in the RESULT array.\n",
    "\n",
    "            Returns:\n",
    "            list: The resulting array.\n",
    "            \"\"\"\n",
    "            RESULT = []\n",
    "\n",
    "            for i in range(len(IN)):\n",
    "                RESULT.append(IN[i])\n",
    "\n",
    "                if len(RESULT) >= 2:\n",
    "                    RESULT = sorted(RESULT)\n",
    "                    l = len(RESULT)\n",
    "                    j = 1\n",
    "                    while j < l:\n",
    "                        if abs(RESULT[j-1] - RESULT[j]) <= dist:\n",
    "                            RESULT[j-1] = min([RESULT[j-1], RESULT[j]])\n",
    "                            RESULT.pop(j)\n",
    "                            l -= 1\n",
    "                            j -= 1\n",
    "                        j += 1\n",
    "                if len(RESULT) == tad_num:\n",
    "                    if information:\n",
    "                        print(f'Found {tad_num} TADs')\n",
    "                    return RESULT\n",
    "\n",
    "            if information:\n",
    "                print(f'Found {len(RESULT)} TADs')\n",
    "            return RESULT\n",
    "\n",
    "        tad_boundaries = create_result_array(\n",
    "            [value[0] for value in sorted(Counter([value for sub_list in process_lists(sums)\n",
    "                                                   for value in sub_list]).items(),\n",
    "                                          key=lambda x: x[1], reverse=True)],\n",
    "            max_num_of_tads, min_tad_size, True)\n",
    "\n",
    "        return tad_boundaries"
   ],
   "id": "4fc574c5b5f9fcd7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:06:19.050059Z",
     "start_time": "2024-06-16T06:06:19.033047Z"
    }
   },
   "cell_type": "code",
   "source": "file_path = r\"Data\\GSE63525_GM12878_diploid_maternal.hic\"",
   "id": "bc81ba2a042a0af2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T06:06:39.779585Z",
     "start_time": "2024-06-16T06:06:39.766581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def do_one_job(chromosome, resolution, smoothing, smoothing_param, max_num_of_tads, min_tad_size):\n",
    "    model = Model()\n",
    "    model.read_data(file_path, chromosome, resolution, smoothing, smoothing_param)\n",
    "    max_r = math.floor(len(model.data)/2)\n",
    "    list_of_averages = model.get_diagonal_averages(max_r)\n",
    "    boundries = model.get_tad_boundaries(max_num_of_tads, min_tad_size, smoothing_param, max_r, list_of_averages)\n",
    "    print(boundries)\n",
    "    model.draw_contact_matrix_with_boundries(boundries)"
   ],
   "id": "5664c3b14b4c59c2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# test which smoothing is the best\n",
    "\n",
    "do_one_job(\"11\", 100000, 1, 10, 10, 10)\n",
    "do_one_job(\"11\", 100000, 2, 10, 10, 10)\n",
    "do_one_job(\"11\", 100000, 3, 10, 10, 10)"
   ],
   "id": "f1aa9b92d1349a88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# test which smoothing_param is the best\n",
    "\n",
    "do_one_job(\"11\", 100000, 3, 2, 10, 10)\n",
    "do_one_job(\"11\", 100000, 3, 5, 10, 10)\n",
    "do_one_job(\"11\", 100000, 3, 10, 10, 10)\n",
    "do_one_job(\"11\", 100000, 3, 20, 10, 10)"
   ],
   "id": "ddcd08a032d6464d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# test which max_num_of_tads is the best\n",
    "\n",
    "do_one_job(\"11\", 100000, 3, 10, 10, 10)\n",
    "do_one_job(\"11\", 100000, 3, 10, 20, 10)\n",
    "do_one_job(\"11\", 100000, 3, 10, 50, 10)"
   ],
   "id": "1ab99f925b77a108"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# test which min_tad_size is the best\n",
    "\n",
    "# do_one_job(\"11\", 100000, 3, 10, 10, 10)\n",
    "# do_one_job(\"11\", 100000, 3, 10, 15, 30)\n",
    "do_one_job(\"11\", 100000, 3, 10, 10, 5)\n",
    "do_one_job(\"11\", 100000, 3, 10, 15, 8)"
   ],
   "id": "48a598eca65892d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "do_one_job(\"17\", 100000, 2, 10, 20, 15)",
   "id": "65bc2ec029afa6b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "do_one_job(\"8\", 100000, 2, 10, 10, 15)",
   "id": "af1f767a932e48a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "do_one_job(\"12\", 100000, 2, 10, 20, 15)",
   "id": "c5bd4231e0bd6f4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "do_one_job(\"19\", 100000, 3, 10, 20, 8)",
   "id": "46c3f589d7dc9322"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "do_one_job(\"20\", 100000, 3, 6, 7, 8)",
   "id": "890c29e3d3894410"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
